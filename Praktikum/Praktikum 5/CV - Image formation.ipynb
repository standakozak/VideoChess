{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image formation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Transformations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load an image and make a translation transformation where you shift the x and y coordinates by some pixels. Do NOT use opencv or other libraries for the transformation.\n",
    "Please use numpy to process the image transformation. You can still use opencv or pillow to load the images.\n",
    "Show the images with matplotlib side by side (original vs transformed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_image(image: np.ndarray, x: int, y: int) -> np.ndarray:\n",
    "    # Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load an image and make a rotation transformation where you rotate the x and y coordinates by some angle. Do NOT use opencv or other libraries for the transformation.\n",
    "Please use numpy to process the image transformation.\n",
    "Show the images with matplotlib side by side (original vs transformed).\n",
    "\n",
    "Hint: Usually the rotation takes place at the top left corner. To rotate the image around the center, you need to shift the image by half the width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image: np.ndarray, rotation_angle: float) -> np.ndarray:\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load an image and make an affine transformation where you transform the x and y coordinates by an affine matrix formulation. Do NOT use opencv or other libraries for the transformation.\n",
    "Please use numpy to process the image transformation.\n",
    "Show the images with matplotlib side by side (original vs transformed).\n",
    "\n",
    "Choose a random affine transformation matrix and apply it to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine(image: np.ndarray, A: np.ndarray) -> np.ndarray:\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projective"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image and make a projective transformation where you transform the x and y coordinates by an projective matrix formulation. Do NOT use opencv or other libraries for the transformation.\n",
    "Please use numpy to process the image transformation.\n",
    "Show the images with matplotlib side by side (original vs transformed).\n",
    "\n",
    "Choose a random homography transformation matrix and apply it to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography(image: np.ndarray, H: np.ndarray) -> np.ndarray:\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera model and projections"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets assume that we have a camera with already known camera intrinsics.\n",
    "We also assume that we know the location of the camera in world coordinates (x, y, z) -> (0, 0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_camera_intrinsics(fov: int, image_width: int, image_height: int) -> np.ndarray:\n",
    "    # Your code here\n",
    "\n",
    "fov = 100\n",
    "image_width, image_height = 640, 480\n",
    "K = create_camera_intrinsics(fov=fov, image_width=image_width, image_height=image_height)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projections between coordinate systems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Define the projection matrix from the world coordinate system into the camera coordinate system.\n",
    "The world coordinate system is defined as follows: x points to the right, y points into the screen and z points up.\n",
    "The camera coordinate systems is defined as follows: x points to the right, y points down and z points into the screen.\n",
    "\n",
    "Name the variable P. P is a 4x4 homogeneous matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "P = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection from a world point cloud into the camera image plane"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We now have both, the camera intrinsics (K) and the camera extrinsics (P).\n",
    "Let us project an arbitrary point cloud into the image plane and store the depth values.\n",
    "\n",
    "Visualize the projected image (depth) afterwards as grayscale image and choose a good scale\n",
    "to make sure that higher depth values are represented brighter than values closer to the camera.\n",
    "\n",
    "How does it look like?\n",
    "\n",
    "Before that, lets take at look at the point cloud visualization first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d  # pip install open3d (on your private computer, not on the THI computer)\n",
    "import os\n",
    "\n",
    "# Load the files as numpy array\n",
    "def load_ply_files(file_dir: str) -> np.ndarray:\n",
    "    # load all files from directory\n",
    "    files = [f for f in os.listdir(file_dir) if f.endswith('.ply')]\n",
    "\n",
    "    # load all files as numpy array\n",
    "    data = []\n",
    "    for file in files:\n",
    "        data.append(np.asarray(o3d.io.read_point_cloud(os.path.join(file_dir, file)).points))\n",
    "    \n",
    "    return np.vstack(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files from plys directory\n",
    "data = load_ply_files('./plys')\n",
    "\n",
    "# open the open3d visualizer\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "\n",
    "# create the point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(data)\n",
    "\n",
    "# add the point cloud to the visualizer\n",
    "vis.add_geometry(pcd)\n",
    "\n",
    "# run the visualizer\n",
    "vis.run()\n",
    "\n",
    "# close the visualizer\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 3D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it is time to project the points from the point cloud into our image plane\n",
    "# As mentioned earlier, the camera is located at (0,0,0) and according to the coordinate system facing into the screen (forward)\n",
    "\n",
    "# First, we need to transform the points from the world coordinate system to the camera coordinate system\n",
    "\n",
    "# From world to camera\n",
    "def world_to_camera(P: np.ndarray, points: np.ndarray) -> np.ndarray:\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, from camera to image plane\n",
    "def camera_to_image_plane(K: np.ndarray, points: np.ndarray, width: int, height: int) -> np.ndarray:\n",
    "    # Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the 3D to 2D projection (plot the image)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Don't forget that the projection, even if its 2D, it still has four dimensions (x, y, 1, 1/z).\n",
    "The last dimension is the inverse depth value.\n",
    "We want to make use of it and plot the depth values as grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_coordinates_to_depth_image(image_coordinates: np.ndarray, width: int, height: int, max_depth: int = -1) -> np.ndarray:\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_coordinates = camera_to_image_plane(K, world_to_camera(P, data), image_width, image_height)\n",
    "\n",
    "plt.imshow(image_coordinates_to_depth_image(image_coordinates, image_width, image_height, 255), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bildverstehen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
